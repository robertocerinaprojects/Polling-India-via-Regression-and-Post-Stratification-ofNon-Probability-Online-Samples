# Polling-India-via-Regression-and-Post-Stratification-of-Non-Probability-Online-Samples

# Abstract:
Recent  technological  advances  have  facilitated  the  collection  of  large-scale  administrative data and the online surveying of the Indian population.  Building on these we propose a strategy for more fine-grained and innovative analyses of the Indian vote.  We execute a modified MrP model of Indian vote preferences that proposes innovations to each of its three core components: stratification frame, training data, and a learner.  For the post-stratification frame we propose a novel Data Integration approach that allows the simultaneous estimation of counts from multiple complementary sources, such as census tables and auxiliary surveys.  For the training data we assemble panels of respondents from two unorthodox online populations:  Amazon MechanicalTurks workers and Facebook users.  And as a modelling tool, we replace the Bayesian multilevel regression learner with Random Forests.  Our 2019 pre-election forecasts for the two largest LokSahba coalitions were very close to actual outcomes:  we predicted 41.6% for the NDA, against an observed value of 45.0% and 30.6% for the UPA against an observed vote share of just under 31.3%.   Our  uniform-swing  seat  projections  outperforms  other  pollsters  â€“  we  had  the  lowest absolute error of 87 seats

# Purpose: 
This repository contains data and code to replicate results. Note that there is a degree of stochasticity to the results due to the various random-sampling steps in the pipeline, and we do not set a seed to avoid giving a false sense of security in the stability of the results. Nevertheless, in our testing we find the degree to which each replica of the results differs from another is very small - up to around 1 % in the national vote-share predictions - and hence any replica is a valid representation of our results, and the procedure we outline. 
